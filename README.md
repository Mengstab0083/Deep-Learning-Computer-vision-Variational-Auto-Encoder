# Deep-Learning-Computer-vision-Variational-Auto-Encoder
defining a Autoencoder (AE) architecture, according the Exercise manual you gives us, The encoder takes an input image and encodes it into a lower-dimensional latent space representation. This is done through convolutional layers followed by fully connected layers, which compresses the input images into a lower-dimensional latent space representation.
The decoder takes a latent space representation and reconstructs the original input image. It does the reverse operation of the encoder, starting with fully connected layers followed by transpose convolutional layers to up sample the representation back to the original image dimensions. And The AE combines the encoder and decoder.
So generally the AE model is trained using mean squared error (MSE) loss between the input and reconstructed images
I modified the AE encoder to output the mean and log variance of the latent distribution instead of directly outputting the latent vector. then sample from this distribution during training and decode the samples in the decoder. So now The encoder (VEncoder) now outputs both the mean (mu) and log variance (logvar) of the latent distribution. And The re parameterize method is used to sample from the latent distribution during training by applying the reparameterization trick. And The forward method of the VAE combines encoding, reparameterization, and decoding.
As you recommended us in the exercise manual I used the reconstruction loss (e.g., Mean Squared Error) and the Kullback-Leibler divergence loss between the learned latent distribution and the prior distribution. I define the binary cross-entropy loss function for reconstruction error and the KL divergence loss function. and also define the complete loss function for the VAE by combining the reconstruction loss and the KL divergence loss. and then I use the Adam optimizer to optimize the parameters of the VAE model.
